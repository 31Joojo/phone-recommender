{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Auteurs : BAUDET Quentin & LARMAILLARD-NOIREN Joris",
   "id": "46e5b371d2614ee3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prototype RAG – Recommandateur de Smartphones  \n",
    "Ce notebook illustre pas à pas :  \n",
    "1. Chargement des données et configuration  \n",
    "2. Construction du jeu de passages + embeddings DPR  \n",
    "3. Création de l’index FAISS  \n",
    "4. Chargement du pipeline RAG Hugging-Face  \n",
    "5. Tests d’interrogation  \n"
   ],
   "id": "f6b2c8aa04c2a27d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chargement des données",
   "id": "7c30820da29e5be5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-07-26T21:21:11.932648Z"
    }
   },
   "source": [
    "### Importation des modules\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizerFast,\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Chargement des variables d'environnement\n",
    "TRANSFORMER = os.getenv('TRANSFORMER')\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "GEN_MODEL = os.getenv(\"GEN_MODEL\")\n",
    "PASSAGES_PATH = os.getenv(\"PASSAGES_PATH\")\n",
    "DPR_DATASET = os.getenv(\"DPR_DATASET\")\n",
    "INDEX_PATH = os.getenv(\"INDEX_PATH\")\n",
    "N_DOCS = int(os.getenv(\"N_DOCS\", 150))\n",
    "DEVICE = os.getenv(\"DEVICE\")"
   ],
   "id": "e38b8ce265f44774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Chargement des données CSV\n",
    "data = pd.read_csv(\"../data/processed/Smartphones_cleaned_dataset_processed.csv\")"
   ],
   "id": "bf1a1a4639323965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Création des passages",
   "id": "8a732a40d666a6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ici, nous allons procéder à la création des passages. On lit le CSV nettoyé et on génère un fichier JSONL de `{\"title\",\"text\"}`, où `title` est le nom de la marque, et le modèle du téléphone, et `text` correspond à toutes les caractéristiques d'un téléphone : c'est-à-dire le prix, la taille d'écran, etc.",
   "id": "ab8cbacd86604705"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "records = []\n",
    "for _, phone in data.iterrows():\n",
    "    title = f\"{phone['brand_name']} {phone['model']}\"\n",
    "    text = (\n",
    "        f\"Prix : {phone['price (€)']} €, Segment du prix : {phone['price_segment']}, \"\n",
    "        f\"Taille d'écran : {phone['screen_size']}”, Taux de rafraîchissement : {phone['refresh_rate']} Hz, \"\n",
    "        f\"Note : {phone['rating']}, Rapport qualité-prix : {phone['quality-price_ratio']}, \"\n",
    "        f\"5G : {'Disponible' if phone['has_5g'] else 'Non disponible'}, \"\n",
    "        f\"Stockage : {phone['internal_memory']} Go, RAM : {phone['ram_capacity']} Go, \"\n",
    "        f\"CPU : {phone['processor_brand']} {round(phone['num_cores'] * phone['processor_speed'], 2)} GHz, \"\n",
    "        f\"Batterie : {phone['battery_capacity']} mAh, Autonomie : {phone['quality_battery_autonomy']}, \"\n",
    "        f\"Charge rapide : {'Non disponible' if phone['fast_charging_available'] == 0 else 'Disponible'}, \"\n",
    "        f\"App. AR : {phone['num_rear_cameras']} ×, App. AV : {phone['num_front_cameras']} ×, \"\n",
    "        f\"Caméra prin. AR : {phone['primary_camera_rear']} Mpx, Caméra prin. AV : {phone['primary_camera_front']} Mpx, \"\n",
    "        f\"OS : {phone['os']}, \"\n",
    "        f\"Niveau de performance : {phone['performance category']}\"\n",
    "    )\n",
    "    records.append({\"title\": title, \"text\": text})\n",
    "\n",
    "### Enregistrement des passages dans un dataset\n",
    "ds = Dataset.from_list(records)\n",
    "\n",
    "### Transformation du contenu du dataset (Les passages) en fichier JSONL\n",
    "ds.to_json(PASSAGES_PATH, orient=\"records\", lines=True)\n",
    "\n",
    "print(\"Passages enregistrés dans\", PASSAGES_PATH)"
   ],
   "id": "a7a976d2fb439f5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Création du dataset DPR et embeddings",
   "id": "90c3fba9fd7823e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ici, il s'agira d'encoder chaque `text` avec Sentence-Transformer et d'ajouter la colonne `embeddings`.",
   "id": "bf0d40da1f7ff093"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Chargement des passages dans un dataset\n",
    "ds = Dataset.from_json(PASSAGES_PATH, split=\"train\")\n",
    "\n",
    "\"\"\"\n",
    "Création d'un embedder pour le calcul des embeddings\n",
    "DEVICE définit quel matériel (Hardware ici) sur lequel nous faisons les calculs des embeddings : CPU ou GPU\n",
    "Transformer : all-MiniLM-L6-v2\n",
    "\"\"\"\n",
    "embedder = SentenceTransformer(TRANSFORMER, device=DEVICE)\n",
    "\n",
    "### Calcul des embeddings\n",
    "embs = embedder.encode(ds[\"text\"], convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "### Ajout de la colonne `embeddings`\n",
    "ds = ds.add_column(\"embeddings\", embs.tolist())\n",
    "\n",
    "### Sauvegarde du dataset\n",
    "ds.save_to_disk(DPR_DATASET)\n",
    "print(\"Dataset DPR sauvé dans\", DPR_DATASET)"
   ],
   "id": "b41e6ad8fbf9e936",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Affichage embeddings**",
   "id": "f2e8df879ee0f558"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Chargement des embeddings\n",
    "embeddings = np.array(ds[\"embeddings\"], dtype=np.float32)\n",
    "\n",
    "### On vérifie ici la dimension des embeddings\n",
    "print(\"Dimension des embeddings:\", embeddings.shape)\n",
    "\n",
    "### Affichage des 5 premiers embeddings\n",
    "print(\"5 premiers embeddings :\", embeddings[:5])"
   ],
   "id": "402c07f77f184ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Création de l’index FAISS",
   "id": "d16a596d722acb08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ici, nous chargeons le dataset DPR, puis extraction des embeddings et on bâtit un `IndexFlatIP`.",
   "id": "73f4006c10de350"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Chargement des embeddings\n",
    "ds2 = load_from_disk(DPR_DATASET)\n",
    "\n",
    "emb_np = np.array(ds2[\"embeddings\"], dtype=np.float32)\n",
    "\n",
    "### Création de l'index\n",
    "index = faiss.IndexFlatIP(emb_np.shape[1])\n",
    "\n",
    "index.add(emb_np)\n",
    "\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "\n",
    "print(\"Index FAISS enregistré dans\", INDEX_PATH)"
   ],
   "id": "95c6746d517394f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Fonction de retrieval DPR  ",
   "id": "c655894adb72f109"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ici, nous allons encoder la question poser par l'utilisateur, et effectuer la recherche dans FAISS.",
   "id": "f6f995051e1f68f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Chargement DPR\n",
    "dpr_tok = DPRQuestionEncoderTokenizerFast.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "dpr_enc = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(DEVICE)\n",
    "\n",
    "faiss_idx = faiss.read_index(INDEX_PATH)\n",
    "passages = ds2[\"text\"]\n",
    "\n",
    "### Fonction retriever\n",
    "def retrieve(q: str, top_k: int = N_DOCS):\n",
    "    ### Encodage de la question - Utilisation du DEVICE\n",
    "    entrees = dpr_tok(q, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        rep = dpr_enc(**entrees)[0].cpu().numpy()\n",
    "\n",
    "    ### Recherche FAISS\n",
    "    scores, ids = faiss_idx.search(rep.astype(np.float32), k=top_k)\n",
    "    \n",
    "    ### Conversion explicite des indices en entier\n",
    "    docs = [(passages[int(i)], float(scores[0, idx])) for idx, i in enumerate(ids[0])]\n",
    "\n",
    "    return docs"
   ],
   "id": "df41cecd2456b562"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Création du modèle avec Google flan-T5",
   "id": "4006f62ffc45b1c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fonction utilitaire pour parser les différentes contraintes de l'utilisateur et charger les éléments directement depuis le dataset",
   "id": "b51925d001168243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_criterion(input_q: str):\n",
    "    question_p = input_q.lower()\n",
    "    if re.search(r\"autonomie|batterie|endurance\", question_p):\n",
    "        return \"battery_capacity\", True\n",
    "    if re.search(r\"photo|nuit|caméra\", question_p):\n",
    "        return \"primary_camera_rear\", True\n",
    "    if re.search(r\"performance|cpu|processeur\", question_p):\n",
    "        return \"processor_speed\", True\n",
    "    if re.search(r\"mémoire vive|ram|stockage\", question_p):\n",
    "        return \"ram_capacity\", True\n",
    "\n",
    "    return None, True"
   ],
   "id": "3f289575b5a01275",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Partie génération Seq2Seq**",
   "id": "48c90678713643b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Mise en place du modèle - Google flan-T5\n",
    "gen_tok = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
    "gen_mod = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    GEN_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ").to(DEVICE)"
   ],
   "id": "c8d3cefc80337c9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def ask(question: str) -> str:\n",
    "    ### Extraction du contexte\n",
    "    docs = retrieve(question)\n",
    "    ### Concentration sur le `text`\n",
    "    passages = [txt for txt,_ in docs]\n",
    "    context = \"\\n\\n\".join(f\"[Doc {i+1}] {txt}\" for i,(txt,_) in enumerate(docs))\n",
    "    \n",
    "    ### Ajout d'exemples pour que le modèle puisse répondre par des phrases structurées et argumentées aux questions posées par l'utilisateur\n",
    "    few_shot = \"\"\"\n",
    "Répondre de manière concise, claire et argumentée par rapport au contexte et à la question.\n",
    "\n",
    "Exemple de réponse attendue :\n",
    "\n",
    "Question : Je veux un smartphone qui tient bien, avec une bonne autonomie et un segment de prix milieu. Quel smartphone me proposerais-tu ?\n",
    "\n",
    "Exemple de réponse attendue :\n",
    "La question porte sur l'autonomie des téléphones. Voici une comparaison basée sur l'autonomie de la batterie de chaque téléphone :\n",
    "- Le modèle [Doc 3] Motorola Moto G40 Fusion se distingue par sa batterie de 5000 mAh, qui lui confère une **autonomie haute**, bien supérieure à celle des autres modèles (3110 mAh et 3240 mAh). Ce modèle est une **meilleure option pour ceux qui cherchent un téléphone avec une bonne autonomie**, en plus de son **rapport qualité-prix intéressant** pour un téléphone dans le segment bas.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = few_shot + \"\\n\" + \\\n",
    "             f\"Contexte :\\n{context}\\n\\n\" + \\\n",
    "             f\"Question : {question}\\nRéponse :\"\n",
    "\n",
    "    inputs = gen_tok(prompt, return_tensors=\"pt\", truncation=True).to(DEVICE)\n",
    "    \n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "    out = gen_mod.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=650,\n",
    "        num_beams=8,\n",
    "        no_repeat_ngram_size=4,\n",
    "        length_penalty=1.2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return gen_tok.decode(out[0], skip_special_tokens=True)\n"
   ],
   "id": "10895023b6fdd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q = (\"Je veux un smartphone qui tient bien, avec une bonne autonomie avec un segment de prix milieu.\")\n",
    "print(\"Q:\", q)\n",
    "print(\"A:\", ask(q), \"\\n\")"
   ],
   "id": "3e9dbdb20f4c5575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Vérification du fonctionnement de FAISS**\n",
   "id": "1932e311b74f5894"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### On teste la récupération de documents pour une question exemple\n",
    "question = \"Je veux un smartphone avec une excellent autonomie.\"\n",
    "\n",
    "### Encodage de la question et calcul des embeddings\n",
    "inputs = dpr_tok(question, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    question_embedding = dpr_enc(**inputs)[0].cpu().numpy()\n",
    "\n",
    "### Recherche des passages les plus proches dans FAISS\n",
    "scores, ids = faiss_idx.search(question_embedding.astype(np.float32), k=10)\n",
    "\n",
    "### Conversion des indices en entier classique\n",
    "for i, identifiant in enumerate(ids[0]):\n",
    "    doc_id = int(identifiant)\n",
    "    print(f\"Doc {i+1}: {passages[doc_id]} (Score: {scores[0][i]})\")"
   ],
   "id": "46d915e005f3b84b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Vérification des colonnes disponibles\n",
    "print(ds.column_names)"
   ],
   "id": "10f4beb1c8362b83",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
